## Welcome to Week 3

This week, we transition from classical methods to the state-of-the-art techniques that power modern NLP. We'll explore the architectures and libraries that have revolutionized the field.

1. **[Transformers](./Transformers/):** We'll dissect the revolutionary transformer architecture, understanding its core components like the attention mechanism and encoder-decoder blocks.
2. **[Hugging Face Library](./Hugging%20Face%20Library/):** You'll get hands-on experience with the transformers library. We'll cover tokenization, loading pre-trained models, and using pipeline for quick applications like sentiment analysis
3. **[Overview of Generative Adversarial Networks](./Overview%20of%20GANs/):** We will take a high-level look at Generative Adversarial Networks (GANs) and their applications within the natural language processing domain.
4. **[Bonus: Diffusion in NLP](./Bonus%20-%20Diffusion%20in%20NLP/):** As a bonus, we'll introduce Diffusion Models, a newer class of generative models, and provide an overview of how they are being adapted for complex text generation tasks.
5. **[Assignments](./Assignments):** It's time to put our knowledge to the test. Let's tackle the assignments and practice our skills to reinforce our understanding.

>[!Note]
For submitting all asignments make a github repo and store the assignments in that repo.
Refer to the [**video**](https://www.youtube.com/watch?v=PQsJR8ci3J0) for making repo.
